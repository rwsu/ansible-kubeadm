- hosts: all
  remote_user: root
  tasks:
    - name: install docker
      yum:
        name: docker
        state: installed

    - name: ensure docker is running
      service:
        name: docker
        state: started
        enabled: yes

    - name: firewall status
      service:
        name: firewalld
        state: stopped
#        enabled: yes

    - name: add kubernetes.repo
      yum_repository:
        name: kubernetes
        description: upstream kubernetes repo
        baseurl: https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
        enabled: yes
        gpgcheck: yes
        repo_gpgcheck: yes
        gpgkey: https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg

    # SELinux needs to be disabled to allow containers to access the host filesystem as
    # required by pod networks. is this really needed??
    - name: set SELinux to permissive
      selinux:
        policy: targeted
        state: permissive

#    - name: install kubelet kubeadm kubectl with version
#      command: yum install -y kubelet-{{ kubernetes_version }} kubeadm-{{ kubernetes_version }} kubectl-{{ kubernetes_version }}
#      when: kubernetes_version is defined

    - name: install kubelet kubeadm kubectl
      command: yum install -y kubelet kubeadm kubectl

    - name: systemctl daemon-reload
      command: systemctl daemon-reload

    - name: ensure kubelet is running
      service:
        name: kubelet
        state: started
        enabled: yes

    - name: disable swap
      command: swapoff -a

- hosts: master
  remote_user: root
  tasks:

  # Open Master node TCP ports (inbound)
  # 6443      Kubernetes API server
  # 2379-2380 etcd server client API
  # 10250     Kubelet API
  # 10251     kube-scheduler
  # 10252     kube-controller-manager
  # 10255     Read-only Kubelet API
    - iptables:
        table: filter
        chain: INPUT
        action: insert
        protocol: tcp
        match: tcp
        ctstate: NEW
        jump: ACCEPT
        destination_port: "{{ item }}"
      become: true
      with_items:
        - 6443
        - 2379:2380
        - 10250
        - 10251
        - 10252
        - 10255
 
#    - name: extra packages
#      yum:
#        name: ansible libvirt-client
#        state: installed

#    - name: run kubeadm init with version
#      shell: kubeadm init --kubernetes-version "{{ kubernetes_version }}" --pod-network-cidr=10.244.0.0/16 | grep "kubeadm join"
#      register: kubeadm_join_command
#      creates: /etc/kubernetes/admin.conf
#      when: kubernetes_version is defined

    - name: run kubeadm init
      shell: kubeadm init --pod-network-cidr=10.244.0.0/16 | grep "kubeadm join"
      register: kubeadm_join_command
      creates: /etc/kubernetes/admin.conf

    - debug:
        var: kubeadm_join_command.stdout_lines

    - name: set join command as fact
      set_fact: joincommand="{{kubeadm_join_command.stdout}}"

    - name: wait for kube-controller to have Running status
      shell: kubectl get pods --kubeconfig /etc/kubernetes/admin.conf --all-namespaces | grep kube-controller
      register: kube_controller_status
      until: kube_controller_status.stdout.find("Running") != -1
      retries: 30
      delay: 10

    - name: copy /etc/kubernetes/admin.conf to ~/.kube/config
      command: cp /etc/kubernetes/admin.conf ~/.kube/config

    - name: install Flannel CNI
#      command: kubectl apply --kubeconfig /etc/kubernetes/admin.conf -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml
      command: kubectl apply --kubeconfig /etc/kubernetes/admin.conf -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
      register: flannel_install 

    - name: wait for kube-dns to have Running status
      shell: kubectl get pods --kubeconfig /etc/kubernetes/admin.conf --all-namespaces | grep dns
      register: kube_dns_status
      until: kube_dns_status.stdout.find("Running") != -1
      retries: 30
      delay: 10

    - name: allow master to schedule pods. needed for gluster 3-node requirement
      command: kubectl taint nodes --all node-role.kubernetes.io/master-

- hosts: worker
  remote_user: root
  tasks:

  # Open Worker node TCP ports (inbound)
  # 10250       Kubelet API
  # 10255       Read-only Kubelet API
  # 30000-32767 NodePort Services

    - iptables:
        table: filter
        chain: INPUT
        action: insert
        protocol: tcp
        match: tcp
        ctstate: NEW
        jump: ACCEPT
        destination_port: "{{ item }}"
      become: true
      with_items:
        - 10250
        - 10255
        - 30000:32767

    - name: join worker node
      command: "{{ hostvars[groups['master'][0]]['joincommand'] }}"